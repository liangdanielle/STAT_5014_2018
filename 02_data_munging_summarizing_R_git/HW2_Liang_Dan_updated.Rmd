---
title: "HW2_Liang_Dan"
author: "Dan Liang"
date: "9/5/2018"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

## Problem 2

## Problem 3

   complete





## Problem 4

1. Vesion control can help us hanlding changes, for example, undo the content we mistakely deleted.
2. Version control storing member's code online for the whole group of members to have access the code. Once one member change the code or submit new function, the version will be updated and the online system will keep the old version in the repository and have the new one, so all members of course project group can get to know that you update your work and have access to check your work. 
3. I can try new code at the same time save the older version. If the new one does not work, just revert it.
4. Through checking the old versions of the code to find out when and where bugs were intruduced, so helps to avoid those next time.

## Problem 5
```{r}
# 5a
library(dplyr)
library(tidyr)

url<-"http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/Sensory.dat"
Sensory<-read.table(url, header=F, skip=1, fill=T, stringsAsFactors = F)
Sensory_cleaned<-Sensory[-1,]
Sensory_cleaned_a<-filter(.data = Sensory_cleaned,V1 %in% 1:10) %>%
                    rename(Item=V1,V1=V2,V2=V3,V3=V4,V4=V5,V5=V6)
Sensory_cleaned_b<-filter(.data = Sensory_cleaned,!(V1 %in% 1:10)) %>%
                    mutate(Item=rep(as.character(1:10),each=2)) %>%
                    mutate(V1=as.numeric(V1)) %>%
                    select(c(Item,V1:V5))
Sensory_cleaned<-bind_rows(Sensory_cleaned_a,Sensory_cleaned_b)
    colnames(Sensory_cleaned)<-c("Item",paste("Person",1:5,sep="_"))
    Sensory_cleaned<-Sensory_cleaned %>%  
        gather(Person,value,Person_1:Person_5) %>%  
        mutate(Person = gsub("Person_","",Person)) %>%
        arrange(Item)
#table
knitr::kable(summary(Sensory_cleaned), caption="Sensory data")

# 5b
url<-"http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/LongJumpData.dat"
    LongJump<-read.table(url, header=F, skip=1, fill=T, stringsAsFactors = F)
    colnames(LongJump)<-rep(c("V1","V2"),4)
    LongJump_cleaned<-rbind(LongJump[,1:2],LongJump[,3:4],
                             LongJump[,5:6],LongJump[,7:8])
    LongJump_cleaned<-LongJump_cleaned %>%  
        filter(!(is.na(V1))) %>%
        mutate(YearCode=V1, Year=V1+1900, dist=V2) %>%
        select(-V1,-V2)
# table
knitr::kable(summary(LongJump_cleaned), caption="Long Jump data")

# 5c
url<-"http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/BrainandBodyWeight.dat"
BrainBody<-read.table(url, header=F, skip=1, fill=T, stringsAsFactors = F)
colnames(BrainBody)<-rep(c("Brain","Body"),3)
    BrainBody_cleaned<-rbind(BrainBody[,1:2],BrainBody[,3:4],
                             BrainBody[,5:6])
    BrainBody_cleaned<-BrainBody_cleaned %>%  
        filter(!(is.na(Brain))) 
# table
knitr::kable(summary(BrainBody_cleaned), caption="Brain/Body weight data")

# 5d
url<-"http://www2.isye.gatech.edu/~jeffwu/wuhamadabook/data/tomato.dat"
    Tomato<-read.table(url, header=F, skip=2, fill=T, stringsAsFactors = F, comment.char = "")
    Tomato_cleaned<-Tomato %>%  
        separate(V2,into=paste("C10000",1:3,sep="_"),sep=",",remove=T, extra="merge") %>%
        separate(V3,into=paste("C20000",1:3,sep="_"),sep=",",remove=T, extra="merge") %>%
        separate(V4,into=paste("C30000",1:3,sep="_"),sep=",",remove=T, extra="merge") %>%
        mutate(C10000_3=gsub(",","",C10000_3)) %>%
        gather(Clone,value,C10000_1:C30000_3) %>%
        mutate(Variety=V1, Clone=gsub("C","",Clone)) %>%
        mutate(Variety=gsub("\\\\#"," ",Variety)) %>%
        separate(Clone,into = c("Clone","Replicate")) %>%
        select(-V1,Variety,Clone,value) %>%
        arrange(Variety) 
# table
knitr::kable(summary(Tomato_cleaned), caption="Tomato")

```


## Problem 6
```{r}
library(swirl)
# Path to data
.datapath <- file.path(path.package('swirl'), 'Courses', 'R_Programming_E', 'Looking_at_Data','plant-data.txt')
# Read in data
plants <- read.csv(.datapath, strip.white=TRUE, na.strings="")
str (plants)
# remove NA in ph_Min and ph_Max
plantcleaned<-filter(plants, !is.na(plants$pH..Minimum) & !is.na(plants$pH..Maximum))
# get mean of ph max and ph min
meanofph <- 2/(plantcleaned$pH..Maximum+plantcleaned$pH..Minimum)
# Use function lm to test for a relationship
fit <- lm(meanofph ~ plantcleaned$Foliage.Color)

summary(fit)


# Use ANOVA 
fit1 <- aov(meanofph ~ plantcleaned$Foliage.Color)
summary(fit1)

```
## Problem 7

### Problem 7a-c

```{r}
# read data Personal:Personal car details; ODefects: observed defects; DetailsD: Defect Details (dataset has been saved and load in R using the codes displayed below)

```
## Problem 7

### Problem 7a-d

```{r}
# read data Personal:Personal car details; ODefects: observed defects; DetailsD: Defect Details (dataset has been saved and load in R)

# Personal <- read.csv('~/Desktop/Personal.csv')
# ODefects <- read.csv('~/Desktop/Defects.csv')
# DetailsD <- read.csv('~/Desktop/Details.csv')


# Merge firt two datasets by licenses (has been merged using the codes displayed below)


# mergebylicense <- merge (Personal,ODefects, by=("Kenteken"))
# Merge the defects details in
# mergebycode <- merge (mergebylicense,DetailsD, by=("Gebrek.identificatie"))

# Remove all NA
# mergecars<- na.omit (mergebycode)

# 5c.count how many different makes and models of cars in 2017, first get subsets of 2017


# install.packages('plyr')
# library (plyr)
```



### Problem 7d
```{r}
# get subset 2017
# defectssubset<- subset (mergecars, mergecars$Meld.datum.door.keuringsinstantie>20170000 & mergecars$Meld.datum.door.keuringsinstantie<20180000)
# get different makes and models of cars using the codes displayed below 
# length(unique(defectssubset$Merk))
# length(unique(defectssubset$Handelsbenaming))
```
    There are 137 types of makes in 2017. There are 2938 types of models in 2017

```{r}
# get subset 2017
# defectssubset<- subset (mergecars, mergecars$Meld.datum.door.keuringsinstantie>20170000 & mergecars$Meld.datum.door.keuringsinstantie<20180000)
# problem 7d, get different makes and models of cars 
# length(unique(defectssubset$Merk))
# length(unique(defectssubset$Handelsbenaming))
# There are 137 types of makes in 2017. There are 2938 types of models in 2017
```



### Problem 7e. 
```{r}
# summary (defectssubset)
```


1. According to the summary of defects in 2017, top five defects are AC1 205 K04 476 210. Also can use sort function to rank the defects.
2. the top five models have the defect are AC1 are PEUGEOT, OPEL, VOLKSWAGENM, CITROEN, VOLVO. The top models have the defect are GOLF, 207, CORSA, POLP, TOYOTA AYGO; 




### Problem 7h. 

1.clean each dataset remove the NA first, then merge would save some times; 
2.try each operation in R script before directly knit the R markdown



